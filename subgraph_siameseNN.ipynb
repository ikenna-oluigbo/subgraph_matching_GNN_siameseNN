{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8938221-f8f5-436f-8993-8f3381fc9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "import ipynb.fs\n",
    "from ipynb.fs.full.graphNN import anchor_pairs, positive_pairs\n",
    "from ipynb.fs.full.graph_features import build_subgraph\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "#Returns dictionary of anchors and positives, with key=subgraph label and value=tensors\n",
    "anchor_tensor = anchor_pairs()\n",
    "positive_tensor = positive_pairs()\n",
    "#_, subgraph_class = build_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53c01e-efbd-4d8a-9613-ec048c65513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs():\n",
    "    _, sub_class = build_subgraph()\n",
    "    imagePairs = []\n",
    "    labelPairs = []\n",
    "    \n",
    "    num_pairs = 15\n",
    "    for i in range(num_pairs):\n",
    "        subgraph_class = sub_class.copy()\n",
    "        \n",
    "        np.random.seed(i)\n",
    "        idx_sub = np.random.choice(subgraph_class)\n",
    "        print(idx_sub)\n",
    "        anchor_sub = anchor_tensor[idx_sub]\n",
    "        positive_sub = positive_tensor[idx_sub]\n",
    "        anchor_sub = tf.expand_dims(anchor_sub, axis=-1)\n",
    "        positive_sub = tf.expand_dims(positive_sub, axis=-1)\n",
    "        \n",
    "        subgraph_class.remove(idx_sub)\n",
    "        idx_diss = np.random.choice(subgraph_class)\n",
    "        print(idx_diss)\n",
    "        diss_sub1 = anchor_tensor[idx_diss]\n",
    "        diss_sub1 = tf.expand_dims(diss_sub1, axis=-1)\n",
    "        \n",
    "        imagePairs.append([anchor_sub, positive_sub])\n",
    "        labelPairs.append([1])\n",
    "                          \n",
    "        imagePairs.append([anchor_sub, diss_sub1])\n",
    "        labelPairs.append([0]) \n",
    "    \n",
    "    return (np.array(imagePairs), np.array(labelPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79001478-6540-4045-a721-d80d828c4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vecs):\n",
    "    (imgA, imgB) = vecs\n",
    "    ss = K.sum(K.square(imgA - imgB), axis = 1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(ss, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcd40e-5833-403f-9b36-328f8b7a0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "\n",
    "def siamese_model(input_shape, embeddingDim = latent_dim):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    x = Conv2D(10, (3, 3), padding = \"same\", activation = \"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(10, (3, 3), padding = \"same\", activation = \"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    pooling = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(embeddingDim)(pooling)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777effe1-c58c-48c9-bf88-a6c3fffc760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastiveLoss(y, y_preds, margin=1):\n",
    "    y = tf.cast(y, y_preds.dtype)\n",
    "    y_preds_squared = K.square(y_preds)\n",
    "    margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
    "    loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870644a3-e962-4b04-98c8-3b94723fbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile():\n",
    "    training_pairs, training_labels = create_pairs()\n",
    "    image_shape = (latent_dim,latent_dim,1)\n",
    "    # specify the batch size and number of epochs\n",
    "    #batch_size = 64\n",
    "    epochs = 50\n",
    "    \n",
    "    imageA = Input(shape = image_shape)\n",
    "    imageB = Input(shape = image_shape)\n",
    "    \n",
    "    model_build = siamese_model(image_shape)\n",
    "    modelA = model_build(imageA)\n",
    "    modelB = model_build(imageB)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance)([modelA, modelB])\n",
    "    model = Model(inputs=[imageA, imageB], outputs=distance)\n",
    "    \n",
    "    model.compile(loss=contrastiveLoss, \n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        [training_pairs[:, 0], training_pairs[:, 1]], training_labels[:],\n",
    "        #validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels[:]),\n",
    "        #batch_size = batch_size,\n",
    "        steps_per_epoch=5,\n",
    "        epochs = epochs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24618a1f-9042-4a6a-9360-86bfde910d56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    model, history = model_compile()\n",
    "    \n",
    "    df = pd.DataFrame(history.history)\n",
    "    epoch = range(len(df.loss))\n",
    "    plt.plot(epoch, df.loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Contrastive Loss')\n",
    "    plt.show() \n",
    "        \n",
    "    test_pairs = create_pairs()[0]\n",
    "    \n",
    "    imageA = test_pairs[:,0]\n",
    "    imageB = test_pairs[:,1]\n",
    "    predicts = model.predict([imageA, imageB]) \n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ed0cb-ad89-40ab-8b59-6243222a4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(result):\n",
    "    len_predict = len(result) \n",
    "    pos_range = np.arange(0, len_predict, 2) \n",
    "    neg_range = pos_range + 1 \n",
    "    \n",
    "    positive_results = np.array([result[i][0] for i in pos_range]) \n",
    "    negative_results = np.array([result[j][0] for j in neg_range])  \n",
    "\n",
    "    for x in range(len(positive_results)):\n",
    "        print('Anchor/Positive: {} - Anchor/Negative: {}'.format(positive_results[x], negative_results[x])) \n",
    "    \n",
    "    plot_prediction(make_predictions())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
